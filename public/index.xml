<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Mr. KnowNothing</title>
    <link>http://localhost:1313/public/</link>
    <description>Recent content on Mr. KnowNothing</description>
    <generator>Hugo -- 0.133.0</generator>
    <language>en</language>
    <lastBuildDate>Wed, 08 May 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/public/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Location</title>
      <link>http://localhost:1313/public/location/</link>
      <pubDate>Wed, 08 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/public/location/</guid>
      <description>Professor Dr von Igelfeld&amp;#39;s mailing and office addresses at the Institute of Romance Philology.</description>
    </item>
    <item>
      <title>DeBerta is new the King</title>
      <link>http://localhost:1313/public/posts/deberta/</link>
      <pubDate>Sat, 12 Feb 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/public/posts/deberta/</guid>
      <description>Describes the working of Deberta , an encoder based Transformer model with Relative Position Encodings</description>
    </item>
    <item>
      <title>LongFormer : The Long Document Transformer</title>
      <link>http://localhost:1313/public/posts/longformer/</link>
      <pubDate>Sat, 12 Feb 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/public/posts/longformer/</guid>
      <description>Describes the working of Longformer , an encoder based Transformer model for Long Sequences</description>
    </item>
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/public/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/public/about/</guid>
      <description>I’m a Lead Machine Learning Engineer at LevelAI, with four years of hands-on experience in NLP, LLMs, and GenAI. My journey into AI wasn’t conventional—I don’t have a formal degree in AI or Computer Science. Instead, I’ve taught myself everything, from the depths of machine learning to its broadest applications. To build a strong foundation, I’ve taken rigorous courses like :
1) Gilbert Strang’s Linear Algebra 2) Stanford CS109 Probability for Computer Scientists by Chris Piech 3) Stanfdord CS231n Convolutional Neural Networks 4) CS224n Natural Language Processing with Deep Learning by Chris Manning and team</description>
    </item>
  </channel>
</rss>
